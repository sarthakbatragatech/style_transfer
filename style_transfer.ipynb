{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Style Transfer\n",
    "\n",
    "Nueral Style Transfer using PyTorch. Original paper by *Leon A. Gatys*, *Alexander S. Ecker* and *Matthias Bethge* [here](https://arxiv.org/abs/1508.06576). Majority of the code used for this repository is authored by *Alexis Jacq* and edited by *Winston Herring*. The link for their article can be found [here](https://pytorch.org/tutorials/advanced/neural_style_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# efficient gradient descents\n",
    "import torch.optim as optim \n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# transform PIL images into tensors\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "#to deep copy the models\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a GPU available, use it! If not, we use the CPU which will take a little longer to run the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are we trying to accomplish?\n",
    "\n",
    "To keep it simple, **Neural Transfer** involves reproducing the contents of an *input image* with the artistic style of a *style image*. For example, can we take the *style* of the watercolor painting below and the *content* of the turtle image in order to produce a third image which is a 'combination' of the two. As you can see, this can lead to very fun results!\n",
    "\n",
    "**Source:** Pytorch Advanced Tutorials\n",
    "![Example](https://pytorch.org/tutorials/_images/neuralstyle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Theory \n",
    "\n",
    "Two distances, one for the content (D<sub>C</sub>) and one for the style (D<sub>S</sub>) are defined. They measure how different two images are content-wise and stylistically. \n",
    "\n",
    "A third image, called the input image, which can be white noise or the content image itself is then transformed so that its content-distance with the content-image and its style-distance with the style-image are both minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the content and style images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original PIL images have values between 0 and 255. These need to be converted to torch tensors, with values between 0 and 1. This is becasue neural networks from the torch library are trained on the same range. Passing inputs in the 0 to 255 range will render the activated feature maps of the network useless. Another important detail is that the *content* and *style* images need to have the same dimensions. We'll resize them to a fixed value to ensure this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use smaller image size if gpu isn't available\n",
    "if torch.cuda.is_available():\n",
    "    imsize = (512, 512) \n",
    "else:\n",
    "    imsize = (256, 256)  \n",
    "\n",
    "# Resize image and transform to torch tensor\n",
    "tfms = [\n",
    "    transforms.Resize(imsize),\n",
    "    transforms.ToTensor()\n",
    "]\n",
    "loader = transforms.Compose(tfms)\n",
    "\n",
    "def image_loader(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    # Insert 1 in shape of the tensor at axis 0\n",
    "    # Extra dimension is required to fit the network's input dimensions\n",
    "    img = loader(img).unsqueeze(0)\n",
    "    return img.to(device, torch.float)\n",
    "\n",
    "\n",
    "style_img = image_loader(\"./data/dali.jpg\")\n",
    "content_img = image_loader(\"./data/sarthak.jpg\")\n",
    "\n",
    "assert style_img.size() == content_img.size(), \\\n",
    "    \"we need to import style and content images of the same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
